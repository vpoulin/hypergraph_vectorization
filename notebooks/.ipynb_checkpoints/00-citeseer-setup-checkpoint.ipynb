{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd1b4c4-2b53-41c2-9edc-7dc06f3ff5ae",
   "metadata": {},
   "source": [
    "## Preparing the 20 Newsgroups Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fab39-c678-4247-b854-938985d091e9",
   "metadata": {},
   "source": [
    "We will need some data to work with. For the purposes of this demo we will make use of the 20 newsgroups dataset. Even though 20 newsgroups is a toy dataset, it offers enough complications to show how we can piece together embeddings using ``vectorizers``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bfc53a-bcae-4a52-b09d-3d2c8d662917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04d8d90-48f5-4971-834f-539a2b2df938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src import paths\n",
    "# from src.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8417332-5659-4467-bec3-472fd2462d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115835a3-ecb6-4440-accc-527f5d841202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca075323-2f86-4db7-9c19-205202c2e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_format_citeseer():\n",
    "    content = pd.read_csv('../data/citeseer-doc-classification/citeseer.content', sep='\\t', header=None)\n",
    "    cites = pd.read_csv('../data/citeseer-doc-classification/citeseer.cites', sep='\\t', header=None)\n",
    "    n = content.shape[1]\n",
    "    \n",
    "    labels = {content.loc[i, 0]: content.loc[i, n-1] for i in range(content.shape[0])}\n",
    "    doc_word_matrix = content[[i+1 for i in range(n-2)]].to_numpy()\n",
    "    citations = cites.groupby(0).aggregate(lambda x: list(x)).reset_index().rename(columns={0:'paper', 1:'citation'})\n",
    "    \n",
    "    return(citations, labels, doc_word_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472d625-2fc1-4afc-a1c5-17f6ab2fc692",
   "metadata": {},
   "source": [
    "With a dataset and a carefully designed color palette we are in good shape to do some analysis of different embedding methods using UMAP to obtain visualizations of the embeddings. \n",
    "\n",
    "## Save this Dataset\n",
    "Let's save this as a dataset for easy re-use in our other notebooks, and add the color palette to the metadata of the dataset. \n",
    "\n",
    "Note: This Dataset has already been added to the catalog and the following cells do not need to be run again. They are included here as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458bd7ef-3727-4e02-9b16-5c223f3891fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.helpers import notebook_as_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd76335-d49d-4982-852f-4f98597684ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset_name = f'{ds_in.name}_pruned'\n",
    "# new_data = news_data\n",
    "# new_target = targets\n",
    "# new_metadata = ds_in.metadata.copy()\n",
    "# new_metadata['color_key'] = color_key\n",
    "# added_descr_txt = f\"\"\"\\n This dataset is a subselection of the {ds_in.name} Dataset where we have pruned out any post less than {prune_limit} \\\n",
    "# characters ({prune_limit} is chosen somewhat arbitrarily). A custom `color_key` can be found in the metadata.\"\"\"\n",
    "# new_metadata['descr'] += added_descr_txt\n",
    "\n",
    "# new_ds = Dataset(dataset_name=new_dataset_name, data=new_data, target=new_target,\n",
    "#                  metadata=new_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a279bef-aabb-4bfc-8257-b38259ca253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:06:53,120 - datasets - WARNING - Overwrite_catalog=True but generate=False. Not overwriting Dataset catalog entry for '20_newsgroups_pruned'\n"
     ]
    }
   ],
   "source": [
    "# # Due to various design choiced in Jupyter, we need to specify this name manually.\n",
    "# nbname = '00-20-newsgroups-setup.ipynb'\n",
    "# dsdict = notebook_as_transformer(notebook_name=nbname,\n",
    "#                                  input_datasets=[ds_in],\n",
    "#                                  output_datasets=[new_ds],\n",
    "#                                  overwrite_catalog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31643cb4-25a7-4cd1-9882-3555014981b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnt_env",
   "language": "python",
   "name": "tnt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
